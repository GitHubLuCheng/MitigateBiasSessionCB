{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import InstagramDataset, VineDataset\n",
    "from dataloader import MyDataLoader\n",
    "from model import HierarchicalAttentionNetwork\n",
    "from utils import get_pretrained_weights\n",
    "from utils import MetricTracker\n",
    "\n",
    "\n",
    "# set device\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device name = %s' %( torch.cuda.get_device_name(device) if device != 'cpu' else 'CPU' ))\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "## Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the config here\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.num_epochs = 25\n",
    "        self.lr = 3e-3\n",
    "        self.max_grad_norm = 5\n",
    "\n",
    "        self.embed_dim = 100\n",
    "        self.word_gru_hidden_dim = 100\n",
    "        self.sent_gru_hidden_dim = 100\n",
    "        self.word_gru_num_layers = 1\n",
    "        self.sent_gru_num_layers = 1\n",
    "        self.word_att_dim = 200\n",
    "        self.sent_att_dim = 200\n",
    "\n",
    "        self.vocab_path = 'data/glove/glove.6B.100d.txt'\n",
    "\n",
    "        # use Glove or not\n",
    "        self.pretrain = True\n",
    "        self.freeze = False\n",
    "\n",
    "        self.use_layer_norm = True\n",
    "        self.dropout = 0.1\n",
    "\n",
    "# get instance\n",
    "config = Config()"
   ]
  },
  {
   "source": [
    "## Load the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data here\n",
    "dataset = InstagramDataset('./data/instagram/instagram_text.tsv')\n",
    "# dataset = VineDataset('./data/vine/vine_full_sessions_pos_970.json', './data/vine/vine_bully.cls')\n",
    "\n",
    "dataset.create_comment_labels()\n",
    "\n",
    "# print data groups dist\n",
    "groups = {0:0, 1:0}\n",
    "for i in range(len(dataset)):\n",
    "    groups[dataset.group[i]] += 1\n",
    "print('Groups Dist:', groups)\n",
    "\n",
    "# create test and train sets\n",
    "test_size = int(len(dataset) * 0.2)\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# create data loaders\n",
    "dataloader = MyDataLoader(train_dataset, config.batch_size)\n",
    "testloader = MyDataLoader(test_dataset, config.batch_size)"
   ]
  },
  {
   "source": [
    "# Define the model here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier here\n",
    "model = HierarchicalAttentionNetwork(\n",
    "    num_classes=dataset.num_classes,\n",
    "    vocab_size=dataset.vocab_size,\n",
    "    embed_dim=config.embed_dim,\n",
    "    word_gru_hidden_dim=config.word_gru_hidden_dim,\n",
    "    sent_gru_hidden_dim=config.sent_gru_hidden_dim,\n",
    "    word_gru_num_layers=config.word_gru_num_layers,\n",
    "    sent_gru_num_layers=config.sent_gru_num_layers,\n",
    "    word_att_dim=config.word_att_dim,\n",
    "    sent_att_dim=config.sent_att_dim,\n",
    "    use_layer_norm=config.use_layer_norm,\n",
    "    dropout=config.dropout).to(device)\n",
    "\n",
    "# load pretrained word embeddings here\n",
    "if config.pretrain:\n",
    "    weights = get_pretrained_weights(\"data/glove\", dataset.vocab, config.embed_dim, device)\n",
    "    model.sent_attention.word_attention.init_embeddings(weights)\n",
    "    model.sent_attention.word_attention.freeze_embeddings(config.freeze)\n",
    "\n",
    "\n",
    "# pretrain the classifier a bit\n",
    "N_CLF_EPOCHS = 5\n",
    "\n",
    "optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=config.lr)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "\n",
    "losses = MetricTracker()\n",
    "accs = MetricTracker()\n",
    "\n",
    "for epoch_idx in range(N_CLF_EPOCHS):\n",
    "    # reset model\n",
    "    model.train()\n",
    "    losses.reset()\n",
    "    accs.reset()\n",
    "\n",
    "    for batch_idx, (docs, labels, doc_lengths, sent_lengths, _) in enumerate(dataloader):\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        docs = docs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        sent_lengths = sent_lengths.to(device)\n",
    "        doc_lengths = doc_lengths.to(device)\n",
    "\n",
    "        scores, word_att_weights, sentence_att_weights = model(docs, doc_lengths, sent_lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(scores, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        if config.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = scores.max(dim=1)[1]\n",
    "        correct_predictions = torch.eq(predictions, labels).sum().item()\n",
    "        acc = correct_predictions\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        accs.update(acc, batch_size)\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('\\tEpoch: [{0}][{1}/{2}]\\t Loss {loss.val:.4f}(avg: {loss.avg:.4f})\\t Acc {acc.val:.3f} (avg: {acc.avg:.3f})'.format(\n",
    "                epoch_idx, batch_idx, len(dataloader), loss=losses, acc=accs))\n",
    "\n",
    "    print('Epoch: [{0}]\\t Avg Loss {loss:.4f}\\t Avg Accuracy {acc:.3f}'.format(epoch_idx, loss=losses.avg, acc=accs.avg))"
   ]
  },
  {
   "source": [
    "## Defining the RL agent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyAgent(nn.Module):\n",
    "    def __init__(self, classifier):\n",
    "        super(PolicyAgent, self).__init__()\n",
    "        self.classifier = classifier\n",
    "        self.softmax_func = nn.Softmax()\n",
    "\n",
    "    def get_action(self, batchloader):\n",
    "        for batch in batchloader:\n",
    "            res = self.classifier(batch[0].to(device), batch[2].to(device), batch[3].to(device))\n",
    "            break\n",
    "        return self.softmax_func(res[0])"
   ]
  },
  {
   "source": [
    "## Define the environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, dataset, testloader, utility_criterion):\n",
    "        self.dataset = dataset\n",
    "        self.testloader = testloader\n",
    "        self.utility_criterion = utility_criterion\n",
    "        self.current_time = 0\n",
    "        self.session_dataset = []\n",
    "\n",
    "        # reset the env\n",
    "        self.reset()\n",
    "\n",
    "    def get_state(self):\n",
    "        # return the comments of a single session 1 by 1\n",
    "        return self.session_dataset[self.current_time], self.label\n",
    "\n",
    "    def reset(self):\n",
    "        # init again!\n",
    "        self.current_time = 0\n",
    "\n",
    "        # select 1 data randomly\n",
    "        random_session, self.label, doc_lengths, sent_lengths, comments_labels = dataset.__getitem__(random.randint(0, len(dataset) - 1), True)\n",
    "\n",
    "        # create different dataloaders\n",
    "        self.session_dataset = []\n",
    "        for t in range(1, len(random_session) + 1):\n",
    "            tmp_session = []\n",
    "            tmp_sent_lengths = []\n",
    "            tmp_comment_labels = []\n",
    "            for i in range(t):\n",
    "                tmp_session.append(random_session[i])\n",
    "                tmp_sent_lengths.append(sent_lengths[i])\n",
    "                tmp_comment_labels.append(comments_labels[i])\n",
    "            \n",
    "            # add to data\n",
    "            self.session_dataset.append(\n",
    "                MyDataLoader([(tmp_session, self.label, len(tmp_session), tmp_sent_lengths, tmp_comment_labels)], batch_size=1)\n",
    "            )\n",
    "\n",
    "    def calc_reward(self, pred_scores, true_labels, alpha=0.5):\n",
    "        loss = self.utility_criterion(pred_scores, true_labels)\n",
    "        true_labels_z_1 = []\n",
    "        true_labels_z_0 = []\n",
    "        pred_labels_z_1 = []\n",
    "        pred_labels_z_0 = []\n",
    "        pred_labels = []\n",
    "        true_test = []\n",
    "\n",
    "        # calculate the fairness measure as well\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (docs, labels, doc_lengths, sent_lengths, z) in enumerate(self.testloader):\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                docs = docs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                sent_lengths = sent_lengths.to(device)\n",
    "                doc_lengths = doc_lengths.to(device)\n",
    "\n",
    "                scores, _, _ = model(docs, doc_lengths, sent_lengths)\n",
    "\n",
    "                # Compute accuracy\n",
    "                predictions = scores.max(dim=1)[1]\n",
    "\n",
    "                for i, pred in enumerate(predictions):\n",
    "                    if z[i] == 1:\n",
    "                        pred_labels_z_1.append(pred.item())\n",
    "                        true_labels_z_1.append(labels[i].item())\n",
    "                    else:\n",
    "                        pred_labels_z_0.append(pred.item())\n",
    "                        true_labels_z_0.append(labels[i].item())\n",
    "                    pred_labels.append(pred.item())\n",
    "                    true_test.append(labels[i].item())\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(true_test, pred_labels).ravel()\n",
    "        FPR_overall = fp / (fp + tn + 1e-10)\n",
    "        FNR_overall = fn / (fn + tp + 1e-10)\n",
    "\n",
    "        FPR_z = []\n",
    "        FNR_z = []\n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels_z_1, pred_labels_z_1).ravel()\n",
    "        FPR_z.append(fp / (fp + tn + 1e-10))\n",
    "        FNR_z.append(fn / (fn + tp + 1e-10))\n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels_z_0, pred_labels_z_0).ravel()\n",
    "        FPR_z.append(fp / (fp + tn + 1e-10))\n",
    "        FNR_z.append(fn / (fn + tp + 1e-10))\n",
    "\n",
    "        FNED = 0\n",
    "        FPED = 0\n",
    "        for fp in FPR_z:\n",
    "            FPED += abs(fp - FPR_overall)\n",
    "        for fn in FNR_z:\n",
    "            FNED += abs(fn - FNR_overall)\n",
    "\n",
    "        return loss + alpha * (2 / ((1 / (FNED + 1e-10)) + (1 / (FPED + 1e-10))))\n",
    "\n",
    "    def perform_action(self, pred_score, true_label):\n",
    "        # action is the label\n",
    "        self.current_time += 1\n",
    "        \n",
    "        # check if finished!\n",
    "        done = True if self.current_time >= len(self.session_dataset) else False\n",
    "\n",
    "        # calculate the reward etc.\n",
    "        return self.calc_reward(pred_score, true_label), done\n",
    "\n",
    "\n",
    "## helper functions\n",
    "def calc_discounted_rewards(rewards, gamma):\n",
    "    returns = []\n",
    "    \n",
    "    for t in range(len(rewards)):\n",
    "        ret = 0\n",
    "        \n",
    "        for t_p in range(t, len(rewards)):\n",
    "            ret += gamma ** (t_p - t) * rewards[t_p]\n",
    "            \n",
    "        returns.insert(0, ret)\n",
    "        \n",
    "    return returns\n",
    "\n",
    "def calc_discounted_rewards_better(rewards, gamma):\n",
    "    returns = []\n",
    "    \n",
    "    for p, r in enumerate(rewards):\n",
    "        returns.append((gamma ** p) * r)\n",
    "\n",
    "    returns = np.cumsum(returns[::-1])\n",
    "    \n",
    "    return returns"
   ]
  },
  {
   "source": [
    "## Run the RL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GAMMA           = 0.1\n",
    "MAX_EPISODES    = 500\n",
    "BASELINE_REWARD = 'mean'\n",
    "\n",
    "env = Env(train_dataset, dataloader, nn.CrossEntropyLoss(reduction='sum').to(device))\n",
    "agent = PolicyAgent(model).to(device)\n",
    "optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "episode_rewards = []\n",
    "\n",
    "agent.train()\n",
    "softmax_func = nn.Softmax()\n",
    "\n",
    "for episode_no in range(MAX_EPISODES):\n",
    "    rewards = []\n",
    "    action_probs = []\n",
    "    actions = []\n",
    "    \n",
    "    done = False\n",
    "    env.reset()\n",
    "    current_state, true_label = env.get_state()\n",
    "    \n",
    "    # go through an episode\n",
    "    while not done:\n",
    "        # get action\n",
    "        action_dist = agent.get_action(current_state) \n",
    "        p = action_dist.detach().cpu().flatten()\n",
    "        action = np.random.multinomial(1, p)[0]\n",
    "        reward, done = env.perform_action(action_dist, torch.tensor([true_label]).to(device))\n",
    "        \n",
    "        # save\n",
    "        rewards.append(-1 * reward.item())\n",
    "        actions.append(action)\n",
    "        action_probs.append(action_dist)\n",
    "\n",
    "        # go next\n",
    "        if done:\n",
    "            break\n",
    "        current_state, true_label = env.get_state()\n",
    "    \n",
    "    # update network after an episode -> monte carlo\n",
    "    returns = calc_discounted_rewards(rewards, GAMMA)\n",
    "    \n",
    "    # calculate loss value\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(rewards)):\n",
    "        loss += action_probs[i][0, actions[i]] * returns[i]\n",
    "\n",
    "    if BASELINE_REWARD == 'mean':\n",
    "        loss = (loss - np.mean(returns)) / len(rewards)\n",
    "    else:\n",
    "        loss = (loss - BASELINE_REWARD) / len(rewards)\n",
    "    \n",
    "    # update network params\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if config.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print \n",
    "    episode_rewards.append(np.sum(rewards))\n",
    "    if episode_no % 10 == 0:\n",
    "        print('[%d/%d] Mean Reward = %0.4f   Max Reward = %0.4f\\t\\t\\t' %(episode_no, MAX_EPISODES, np.mean(episode_rewards[-50:]), np.max(episode_rewards[-50:])))\n",
    "    if episode_no % 100 == 0:\n",
    "        # save the fair model\n",
    "        torch.save({\n",
    "            'epoch': 200,\n",
    "            'model': model,\n",
    "            'optimizer': optimizer,\n",
    "        }, 'best_model/vine_rl_model_it_%d.pth.tar' %(episode_no))"
   ]
  },
  {
   "source": [
    "## Save the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fair model\n",
    "torch.save({\n",
    "    'epoch': 5,\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "}, 'best_model/model.pth.tar')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}